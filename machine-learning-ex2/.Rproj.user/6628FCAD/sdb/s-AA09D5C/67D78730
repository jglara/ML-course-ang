{
    "collab_server" : "",
    "contents" : "%% Machine Learning Online Class - Exercise 2: Logistic Regression\n%\n%  Instructions\n%  ------------\n% \n%  This file contains code that helps you get started on the logistic\n%  regression exercise. You will need to complete the following functions \n%  in this exericse:\n%\n%     sigmoid.m\n%     costFunction.m\n%     predict.m\n%     costFunctionReg.m\n%\n%  For this exercise, you will not need to change any code in this file,\n%  or any other files other than those mentioned above.\n%\n\n%% Initialization\nclear ; close all; clc\n\n%% Load Data\n%  The first two columns contains the exam scores and the third column\n%  contains the label.\n\ndata = load('ex2data1.txt');\nX = data(:, [1, 2]); y = data(:, 3);\n\n%% ==================== Part 1: Plotting ====================\n%  We start the exercise by first plotting the data to understand the \n%  the problem we are working with.\n\nfprintf(['Plotting data with + indicating (y = 1) examples and o ' ...\n         'indicating (y = 0) examples.\\n']);\n\nplotData(X, y);\n\n% Put some labels \nhold on;\n% Labels and Legend\nxlabel('Exam 1 score')\nylabel('Exam 2 score')\n\n% Specified in plot order\nlegend('Admitted', 'Not admitted')\nhold off;\n\nfprintf('\\nProgram paused. Press enter to continue.\\n');\npause;\n\n\n%% ============ Part 2: Compute Cost and Gradient ============\n%  In this part of the exercise, you will implement the cost and gradient\n%  for logistic regression. You neeed to complete the code in \n%  costFunction.m\n\n%  Setup the data matrix appropriately, and add ones for the intercept term\n[m, n] = size(X);\n\n% Add intercept term to x and X_test\nX = [ones(m, 1) X];\n\n% Initialize fitting parameters\ninitial_theta = zeros(n + 1, 1);\n\n% Compute and display initial cost and gradient\n[cost, grad] = costFunction(initial_theta, X, y);\n\nfprintf('Cost at initial theta (zeros): %f\\n', cost);\nfprintf('Expected cost (approx): 0.693\\n');\nfprintf('Gradient at initial theta (zeros): \\n');\nfprintf(' %f \\n', grad);\nfprintf('Expected gradients (approx):\\n -0.1000\\n -12.0092\\n -11.2628\\n');\n\n% Compute and display cost and gradient with non-zero theta\ntest_theta = [-24; 0.2; 0.2];\n[cost, grad] = costFunction(test_theta, X, y);\n\nfprintf('\\nCost at test theta: %f\\n', cost);\nfprintf('Expected cost (approx): 0.218\\n');\nfprintf('Gradient at test theta: \\n');\nfprintf(' %f \\n', grad);\nfprintf('Expected gradients (approx):\\n 0.043\\n 2.566\\n 2.647\\n');\n\nfprintf('\\nProgram paused. Press enter to continue.\\n');\npause;\n\n\n%% ============= Part 3: Optimizing using fminunc  =============\n%  In this exercise, you will use a built-in function (fminunc) to find the\n%  optimal parameters theta.\n\n%  Set options for fminunc\noptions = optimset('GradObj', 'on', 'MaxIter', 400);\n\n%  Run fminunc to obtain the optimal theta\n%  This function will return theta and the cost \n[theta, cost] = ...\n\tfminunc(@(t)(costFunction(t, X, y)), initial_theta, options);\n\n% Print theta to screen\nfprintf('Cost at theta found by fminunc: %f\\n', cost);\nfprintf('Expected cost (approx): 0.203\\n');\nfprintf('theta: \\n');\nfprintf(' %f \\n', theta);\nfprintf('Expected theta (approx):\\n');\nfprintf(' -25.161\\n 0.206\\n 0.201\\n');\n\n% Plot Boundary\nplotDecisionBoundary(theta, X, y);\n\n% Put some labels \nhold on;\n% Labels and Legend\nxlabel('Exam 1 score')\nylabel('Exam 2 score')\n\n% Specified in plot order\nlegend('Admitted', 'Not admitted')\nhold off;\n\nfprintf('\\nProgram paused. Press enter to continue.\\n');\npause;\n\n%% ============== Part 4: Predict and Accuracies ==============\n%  After learning the parameters, you'll like to use it to predict the outcomes\n%  on unseen data. In this part, you will use the logistic regression model\n%  to predict the probability that a student with score 45 on exam 1 and \n%  score 85 on exam 2 will be admitted.\n%\n%  Furthermore, you will compute the training and test set accuracies of \n%  our model.\n%\n%  Your task is to complete the code in predict.m\n\n%  Predict probability for a student with score 45 on exam 1 \n%  and score 85 on exam 2 \n\nprob = sigmoid([1 45 85] * theta);\nfprintf(['For a student with scores 45 and 85, we predict an admission ' ...\n         'probability of %f\\n'], prob);\nfprintf('Expected value: 0.775 +/- 0.002\\n\\n');\n\n% Compute accuracy on our training set\np = predict(theta, X);\n\nfprintf('Train Accuracy: %f\\n', mean(double(p == y)) * 100);\nfprintf('Expected accuracy (approx): 89.0\\n');\nfprintf('\\n');\n\n\n",
    "created" : 1513757864066.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4113320160",
    "id" : "67D78730",
    "lastKnownWriteTime" : 1489426802,
    "last_content_update" : 1489426802,
    "path" : "~/git/ML/machine-learning-ex2/ex2/ex2.m",
    "project_path" : "ex2/ex2.m",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "matlab"
}